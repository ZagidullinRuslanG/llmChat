{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# requirements\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "# Загрузка документов\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter\n",
    ")\n",
    "\n",
    "# Эмбеддинги\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "# QnA цепочка\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# model_path = \"./data/weights/mixtral-8x7b-instruct-v0.1.Q6_K.gguf\"\n",
    "model_path = \"./data/weights/openchat_3.5.Q5_K_M.gguf\"\n",
    "# model_path = \"./data/weights/Mistral-7B-Instruct-v0.3.Q6_K.gguf\"\n",
    "\n",
    "embed_model_path = \"./data/weights/intfloat_multilingual-e5-large\"\n",
    "embed_model_path_kwargs = {\"device\": \"cuda:0\"}\n",
    "index_path = \"./data/index\"\n",
    "\n",
    "data_file = \"./data/data/bzd.docx\""
   ],
   "id": "4016735e98115781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path, \n",
    "    temperature=0.2,\n",
    "    max_new_tokens=10000,\n",
    "    context_window=16379-1000,\n",
    "    generate_kwargs={},\n",
    "    # n_ctx=8192,\n",
    "    n_gpu_layers=50, \n",
    "    # n_threads=6, \n",
    "    # n_batch=521, \n",
    "    verbose=True,\n",
    "    callback_manager=callback_manager\n",
    ")"
   ],
   "id": "ad1d2153f1cd2c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = llm.invoke(\n",
    "      \"Q: Кто из знаменитостей родился в год распада СССР? A: \", # Prompt\n",
    "      stop=[\"Q:\", \"\\n\"], \n",
    "      echo=True,\n",
    ") \n",
    "print(res)"
   ],
   "id": "41b6c1645308abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loader = Docx2txtLoader(data_file)\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"Total documents: {len(documents)}\")"
   ],
   "id": "3eaa7d7a7c3890e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=embed_model_path, model_kwargs=embed_model_path_kwargs)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    client_settings=Settings(anonymized_telemetry=True),\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever(k=10)"
   ],
   "id": "79d3debb86f6b738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Устойчивость работы хозяйственного объекта определяется по\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "print(qa_chain.invoke({\"query\": question}))"
   ],
   "id": "e74a19c5f353c353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Аварией считается утечка нефти в щбьеме\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "print(qa_chain.invoke({\"query\": question}))"
   ],
   "id": "f9f19d3c63b6b38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Пожарная техника в зависимости от способа пожаротушения подразделяется на\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "print(qa_chain.invoke({\"query\": question}))"
   ],
   "id": "2741b6b5583581a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Сколько классов опасных производственных объектов существует\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())\n",
    "print(qa_chain.invoke({\"query\": question}))"
   ],
   "id": "ff30a91ce4fbca7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Кто такой джастин бибер?\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "print(qa_chain.invoke({ \"query\": question}))"
   ],
   "id": "358a793c165b7c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sys_templ = '''Ответь на вопрос пользователя на русском языке. \\\n",
    "Используй при этом только информацию из контекста. Если в контексте нет \\\n",
    "информации для ответа, скажи \"Я не знаю\".\n",
    "После основного ответа напиши степень уверенности в ответе. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "'''\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            sys_templ,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# question = \"Кто такой джастин бибер?\"\n",
    "question = \"Аварией считается утечка нефти в обьеме\"\n",
    "# question = \"Устойчивость работы хозяйственного объекта определяется по\"\n",
    "\n",
    "# Поиск по базе данных\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "result = combine_docs_chain.invoke(\n",
    "    {\n",
    "        \"context\": docs,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=question)\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result)"
   ],
   "id": "5b3ad78ea34015b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# question = \"Кто такой джастин бибер?\"\n",
    "question = \"Аварией считается утечка нефти в щбьеме\"\n",
    "# question = \"Устойчивость работы хозяйственного объекта определяется по\"\n",
    "\n",
    "template = '''Ответь на вопрос пользователя на русском языке. \\\n",
    "Используй при этом только информацию из контекста. Если в контексте нет \\\n",
    "информации для ответа, скажи \"Я не знаю\".\n",
    "После основного ответа напиши степень уверенности в ответе. \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Human: {question}\n",
    "Assistant:\n",
    "'''\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "prompt = PromptTemplate(input_variables=[\"context\",  \"question\"], template=template)\n",
    "    \n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever, memory=memory, chain_type_kwargs={'prompt': prompt})\n",
    "print(qa_chain({\"query\": question}))"
   ],
   "id": "45ef39847b406054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e63e00b1c68614c1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
