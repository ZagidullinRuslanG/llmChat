from operator import itemgetter
import os
from config import Config as cfg
from prompts.default_prompts import DEFAULT_SYSTEM_PROMPT, GLOSSARY
import torch
from chat_folder.chat_script import *

import gradio as gr
from chat_folder.terminal_parse import get_ollama_model_list


def get_chat_ui():


    msg_box = gr.Textbox(container=False, show_label=False,
        label="Message",
        placeholder="–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...",
        scale=7,
        autofocus=True,
        )

    with gr.Blocks(fill_height=True, css=".block  .svelte-12cmxck { height:calc(100vh - 380px)!important; }") as block:

        #     allocMem = gr.Markdown()
        # with gr.Column(scale=1):
        #     button = gr.Button(value="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∏–¥–µ–æ–ø–∞–º—è—Ç—å" , size="sm" , scale=1)
        #     button.click(getAllocMem, outputs=[allocMem])

        with gr.Accordion("–ù–∞—Å—Ç—Ä–æ–π–∫–∏", open=False):
            

            sys_prompt = gr.Textbox(label='–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç', value=DEFAULT_SYSTEM_PROMPT)
            glossary = gr.Textbox(label='–°–ª–æ–≤–∞—Ä—å', value=GLOSSARY)
            temp = gr.Slider(minimum=0, maximum=1, step=0.05, value=cfg.TEMPERATURE, label='–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞')

            n_ctx = gr.Slider(minimum=1024, maximum=1024*126, step=1024, value=cfg.N_CTX, label='–†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞')

            n_nodes_ctx = gr.Slider(minimum=0, maximum=cfg.SIMILARITY_TOP_K+20, step=1, value=cfg.SIMILARITY_TOP_K, label='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞')
            max_threshold_ctx = gr.Slider(minimum=0, maximum=1, step=0.01, value=cfg.SIMILARITY_CUTOFF, label='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞')

            model_list, starting_model = get_ollama_model_list(in_one_line=True, find_starting=cfg.START_MODEL_NAME)
            print(model_list, starting_model)
            model_dropdown = gr.Dropdown(model_list, label='–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏', value = starting_model, interactive=True)

            update_config_btn = gr.Button(value='–û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥')
            update_config_btn.click(fn = update_model_from_config, inputs=[
                model_dropdown,
                sys_prompt, glossary, temp, n_nodes_ctx, max_threshold_ctx, n_ctx
                ])
            

            flush_cache_btn = gr.Button(value = '–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â–∏–π VRAM')
            flush_cache_btn.click(fn = flush_VRAM)

            stop_ollama_model_btn = gr.Button(value = '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å Ollama')
            stop_ollama_model_btn.click(stop_ollama_model)

            flush_VRAM_after_use = gr.Checkbox(value=True, label='–û—á–∏—â–∞—Ç—å VRAM –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –∑–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏')
            flush_VRAM_after_use.change(fn = change_flush_after_use, inputs=[flush_VRAM_after_use])

            preload_ollama_model_btn = gr.Button(value='–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏')
            preload_ollama_model_btn.click(fn = preload_ollama_model)

            # slider
            

        with gr.Accordion("–ö–æ–Ω—Ç–µ–∫—Å—Ç", open=False):
            embed_timer = gr.Timer(1)

            embed_log = gr.TextArea(value="Embedding text will be here", label='Context')
            prompt_log = gr.TextArea(value="Your prompt text will be here", label='Prompt')
            embed_timer.tick(fn = update_embed_log, inputs=[embed_timer], outputs=[embed_log, prompt_log])
            
        

        # TODO: str –∫–Ω–æ–ø–∫–∏ –Ω–µ –æ—á–∏—â–∞—é—Ç –∏—Å—Ç–æ—Ä–∏—é –±–æ—Ç–∞, —Å–¥–µ–ª–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∫–Ω–æ–ø–∫–∏

        chatbot = gr.Chatbot(
                    elem_id="chatbot",
                    height=800,
                )

        chat = gr.ChatInterface(fn = stream_response, #additional_outputs=[nodes, res_prompt], # only with custom gradio
            additional_inputs=[temp, sys_prompt, glossary, n_nodes_ctx, max_threshold_ctx],
            title='ERACHAT',
            chatbot=chatbot,
            submit_btn='–û—Ç–ø—Ä–∞–≤–∏—Ç—å',
            retry_btn='üîÑ  –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å',
            undo_btn= 'üîô  –û—Ç–º–µ–Ω–∏—Ç—å',
            clear_btn='üóëÔ∏è  –û—á–∏—Å—Ç–∏—Ç—å',
            textbox = msg_box,
            examples=[['–ß—Ç–æ —Ç–∞–∫–æ–µ –±—Ä–∏–≥–∞–¥–∞?'], ['–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–∫–≤–∞–∂–∏–Ω–∞?'], ['–°–æ–∫—Ä–∞—Ç–∏ –æ—Ç–≤–µ—Ç'], ['–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–∫–≤–∞–∂–∏–Ω–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç? –ü—Ä–∏–≤–µ–¥–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –∫–∞–∫ –µ–µ –¥–æ–±–∞–≤–∏—Ç—å.'], ['–ü—Ä–∏–≤–µ–¥–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –∫–∞–∫ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∫–≤–∞–∂–∏–Ω—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.']])

        chat.load(fn = update_model_from_config, inputs=[
            model_dropdown,
            sys_prompt, glossary, temp, n_nodes_ctx, max_threshold_ctx, n_ctx
            ])
        

        header_log = gr.Markdown(chat_update())

        header_log_timer = gr.Timer(1)
        header_log_timer.tick(fn = chat_update, outputs=[header_log])
            
        # chat.chatbot.change(fn = chat_update, outputs=[header_log])
            
        return block
